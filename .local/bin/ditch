#!/bin/sh --
# ditch - display menu of twitch streamers currently online
# requres jq curl bemenu mpv youtube-dl

# TODO
#   - If the file 'livestreams' exists and is not within the cache time limit
#     it will be used regardless of new inputs.  The flag '-f' forces a cache
#     bypass, but I do not favour this approach.

# XXX I am not aware of a maximum query limit for the number of users or
#     whether this may change.
maxquery=500
cachedir=${XDG_CACHE_HOME:-$HOME/.cache}/ditch
mkdir -p -- "$cachedir"

renew=$(touch -d "$(TZ=UTC+00:10:00 date +%Y-%m-%dT%T)" -- "$cachedir"/timeref
        find "$cachedir"/livestreams ! -newer "$cachedir"/timeref
        rm -f -- "$cachedir"/timeref)

if [ -s "$cachedir"/livestreams ] && ! { [ "$renew" ] || [ "$1" = -f ] ;}; then
    cat -- "$cachedir"/livestreams
else
    tmp=${TMPDIR:-/tmp}/ditch_$$
    mkdir -p -- "$tmp"/data

    # shellcheck disable=SC1004
    awk -v m="$maxquery" -v tmp="$tmp"/data '
        function writequery(s, dest){
            printf("[{\"query\":\"query{users(logins:[%s]){login\\nstream{" \
                   "title\\nviewersCount\\ngame{name}\\n}}}\"}]", s) > dest
        }
        !((NR-1) % m) {if(users) writequery(users, tmp "/" NR); users = ""}
        NF && !/^#/   {users = users "\\\"" $1 "\\\""}
        END           {if(users) writequery(users, tmp "/" NR)}'

    for data in "$tmp"/data/*; do
        if [ -f "$data" ]; then
            # N.B. Placing 'next' first in the config seems harmless, whereas if
            #      it were last curl would warn of a missing url.
            printf 'next\n'
            printf 'url https://api.twitch.tv/gql\n'
            printf 'header "Client-ID: kimne78kx3ncx6brgo4mv6wki5h1ko"\n'
            printf 'data "@%s"\n' "$data"
            printf 'output "%s"\n' "$tmp"/"${data##*/}"
            printf 'write-out %%{filename_effective}\\n\n'
        fi
    # N.B. cat is used to ensure a single stream of a json is produced in order
    #      to avoid xargs spreading the arguments across multiple invocations
    #      of jq according to ARG_MAX.
    done | curl --parallel-max 15 -sSZK - \
         | xargs -E '' cat \
         | jq -sr '[.[][].data.users[] | select(.stream != null)]
                   | sort_by(-.stream.viewersCount)[]
                   | [.login, .stream.game.name[:50], .stream.title]
                   | @tsv' \
         | column -ts '	' \
         | tee "$cachedir"/livestreams

    rm -rf -- "$tmp"
fi | menu --ifne -l 30 -p STREAM | while read -r user _; do
        if [ "$user" ]; then
            printf '%s\n' "$user" >> "$cachedir"/stats
            mpv --quiet https://twitch.tv/"$user" &
        fi
    done
